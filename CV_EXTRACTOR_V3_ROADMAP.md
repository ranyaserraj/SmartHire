# ğŸš€ CV Extractor V3 - Roadmap ComplÃ¨te

## ğŸ“Š Ã‰tat des Lieux

### âœ… DÃ©jÃ  ImplÃ©mentÃ© dans V2

| FonctionnalitÃ© | Statut | QualitÃ© |
|----------------|--------|---------|
| pdfplumber (au lieu de PyPDF2) | âœ… Fait | Bon |
| rapidfuzz (fuzzy matching) | âœ… Fait | Partiel |
| Patterns de dates multiples | âœ… Fait | Partiel |
| DÃ©tection sections (regex) | âœ… Fait | Basique |
| Extraction tÃ©lÃ©phone | âœ… Fait | Bon |
| Stopwords (150+ mots) | âœ… Fait | Excellent |
| Extraction compÃ©tences | âœ… Fait | Moyen |

### âŒ Manquant / Ã€ AmÃ©liorer

| FonctionnalitÃ© | PrioritÃ© | ComplexitÃ© | Impact |
|----------------|----------|------------|--------|
| **ESCO (13 000+ skills)** | ğŸ”´ HAUTE | Moyenne | â­â­â­â­â­ |
| Tri blocs par position (x, y) | ğŸ”´ HAUTE | Haute | â­â­â­â­â­ |
| Fuzzy matching sections | ğŸ”´ HAUTE | Faible | â­â­â­â­ |
| Dates avec sÃ©parateurs (â†’, â€“, >) | ğŸŸ  MOYENNE | Faible | â­â­â­â­ |
| Regroupement lignes logiques | ğŸŸ  MOYENNE | Moyenne | â­â­â­â­ |
| Split compÃ©tences (,  ;  â€¢) | ğŸŸ  MOYENNE | Faible | â­â­â­â­ |
| OCR traineddata FR/EN/AR | ğŸŸ  MOYENNE | Moyenne | â­â­â­ |
| DÃ©tection nom intelligente | ğŸŸ  MOYENNE | Moyenne | â­â­â­â­ |
| Extraction adresse complÃ¨te | ğŸŸ¡ BASSE | Moyenne | â­â­â­ |
| Langues + niveaux CEFR | ğŸŸ¡ BASSE | Faible | â­â­â­ |
| Formation intelligente | ğŸŸ  MOYENNE | Moyenne | â­â­â­â­ |
| ExpÃ©riences sans section | ğŸŸ  MOYENNE | Haute | â­â­â­â­ |
| NLP avec spaCy | ğŸŸ¡ BASSE | Haute | â­â­â­ |
| Soft skills automatiques | ğŸ”´ HAUTE | Moyenne | â­â­â­â­â­ |
| DÃ©tection multi-langue | ğŸŸ¡ BASSE | Faible | â­â­ |

---

## ğŸ¯ Phase 1 : AmÃ©liorations Critiques (PrioritÃ© HAUTE)

### 1.1 IntÃ©gration ESCO â­â­â­â­â­

**Pourquoi :** Dataset officiel de l'UE avec 13 000+ compÃ©tences en 28 langues

**Comment :**
```python
# backend/data/esco_skills_sample.json (dÃ©jÃ  crÃ©Ã©)
# Contient 96 compÃ©tences techniques + 43 soft skills

# Ã€ faire :
# 1. TÃ©lÃ©charger le dataset complet ESCO
# 2. Parser et indexer les skills
# 3. Remplacer tech_skills_base par ESCO
```

**Fichiers Ã  modifier :**
- `cv_extractor_v3.py` : Charger ESCO au __init__
- `data/esco_skills_sample.json` : Fichier temporaire (139 skills)
- `data/esco_skills_full.json` : Dataset complet (13 000+)

**Avantages :**
- âœ… 13 000+ compÃ©tences vs 96 actuellement
- âœ… Traductions FR/EN/ES/DE/etc.
- âœ… Classification hard/soft skills
- âœ… CompÃ©tences liÃ©es aux mÃ©tiers
- âœ… Mis Ã  jour rÃ©guliÃ¨rement par l'UE

**Code :**
```python
class CVExtractorV3:
    def __init__(self):
        # Charger ESCO
        self.esco_skills = self._load_esco_skills()
    
    def _load_esco_skills(self):
        data_file = Path(__file__).parent.parent / "data" / "esco_skills_sample.json"
        with open(data_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _extract_skills_esco(self, text: str) -> List[str]:
        skills_found = set()
        
        # Chercher toutes les compÃ©tences ESCO
        for skill in self.esco_skills['technical_skills']:
            if re.search(r'\b' + re.escape(skill.lower()) + r'\b', text.lower()):
                skills_found.add(skill)
        
        for skill in self.esco_skills['soft_skills']:
            if re.search(r'\b' + re.escape(skill.lower()) + r'\b', text.lower()):
                skills_found.add(skill)
        
        return sorted(list(skills_found))
```

---

### 1.2 Tri des Blocs par Position Spatiale (x, y) â­â­â­â­â­

**ProblÃ¨me actuel :** CV en 2 colonnes â†’ texte extrait dans le mauvais ordre

**Solution :** Utiliser pdfplumber pour extraire les coordonnÃ©es et trier

```python
def _extract_from_pdf_spatial(self, file_path: Path) -> str:
    """Extraction avec tri spatial pour CV en colonnes"""
    text_blocks = []
    
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            # Extraire les mots avec coordonnÃ©es
            words = page.extract_words(
                x_tolerance=3,
                y_tolerance=3,
                keep_blank_chars=False
            )
            
            # Regrouper par lignes (mÃªme y)
            lines = {}
            for word in words:
                y = round(word['top'])
                if y not in lines:
                    lines[y] = []
                lines[y].append((word['x0'], word['text']))
            
            # Trier chaque ligne de gauche Ã  droite
            for y in sorted(lines.keys()):
                line_words = sorted(lines[y], key=lambda x: x[0])
                line_text = ' '.join([w[1] for w in line_words])
                text_blocks.append(line_text)
    
    return '\n'.join(text_blocks)
```

**Impact :**
- âœ… CV en 2 colonnes correctement lus
- âœ… CV en tableaux bien parsÃ©s
- âœ… Ordre de lecture "humain"

---

### 1.3 Fuzzy Matching pour DÃ©tection de Sections â­â­â­â­

**ProblÃ¨me actuel :**
```python
if keyword in line_lower:  # Trop strict
```

**Ne dÃ©tecte pas :**
- `WORK EXPERIENCE` (espace)
- `EXPÃ‰RIENCES PROFESSIONNELLES` (accent)
- `EXPÃ‰RIENCE â€”` (caractÃ¨re spÃ©cial)
- `[ğŸ”§ ICON] Experience` (avec icÃ´ne)
- `EXPERIENCE` (stylisÃ©)

**Solution :** Fuzzy matching avec rapidfuzz

```python
def _detect_sections_fuzzy(self, lines: List[str]) -> Dict[str, List[str]]:
    """DÃ©tection de sections avec fuzzy matching"""
    sections = {}
    current_section = None
    current_content = []
    
    section_keywords = {
        'experience': ['experience', 'work experience', 'employment', 'career'],
        'formation': ['education', 'formation', 'studies', 'degree'],
        'competences': ['skills', 'competences', 'expertise', 'abilities'],
    }
    
    for line in lines:
        line_clean = re.sub(r'[^\w\s]', '', line.lower())  # Enlever symboles
        
        # Tester chaque type de section
        section_detected = None
        best_score = 0
        
        for section_name, keywords in section_keywords.items():
            for keyword in keywords:
                score = fuzz.partial_ratio(keyword, line_clean)
                if score > 85 and score > best_score:  # 85% de similaritÃ©
                    section_detected = section_name
                    best_score = score
        
        if section_detected:
            # Sauvegarder la section prÃ©cÃ©dente
            if current_section and current_content:
                sections[current_section] = current_content
            
            current_section = section_detected
            current_content = []
        elif current_section:
            current_content.append(line)
    
    # Sauvegarder la derniÃ¨re section
    if current_section and current_content:
        sections[current_section] = current_content
    
    return sections
```

**Impact :**
- âœ… DÃ©tecte sections mÃªme avec typos
- âœ… GÃ¨re les accents et caractÃ¨res spÃ©ciaux
- âœ… Ignore les icÃ´nes et symboles
- âœ… Fonctionne en FR et EN

---

### 1.4 Soft Skills Automatiques (ESCO) â­â­â­â­â­

**Actuellement :** Liste manuelle de 43 soft skills

**Avec ESCO :** Reconnaissance automatique de centaines de soft skills

```python
def _extract_soft_skills_esco(self, text: str) -> List[str]:
    """Extraction des soft skills depuis ESCO"""
    soft_skills_found = set()
    text_lower = text.lower()
    
    # Chercher toutes les soft skills ESCO
    for skill in self.esco_skills.get('soft_skills', []):
        # Recherche exacte
        if re.search(r'\b' + re.escape(skill.lower()) + r'\b', text_lower):
            soft_skills_found.add(skill)
        # Fuzzy match pour variations
        else:
            words = text.split()
            matches = process.extract(skill, words, scorer=fuzz.ratio, limit=1)
            if matches and matches[0][1] > 90:  # 90% de similaritÃ©
                soft_skills_found.add(skill)
    
    return sorted(list(soft_skills_found))
```

**Soft Skills dÃ©tectÃ©es automatiquement :**
- Leadership, Team Management, Project Management
- Communication, Public Speaking, Negotiation
- Problem Solving, Critical Thinking, Analytical Skills
- Adaptability, Creativity, Innovation
- Time Management, Organization, Attention to Detail
- Gestion d'Ã©quipe, Travail en Ã©quipe, RÃ©solution de problÃ¨mes
- etc.

---

## ğŸ¯ Phase 2 : AmÃ©liorations Moyennes (PrioritÃ© MOYENNE)

### 2.1 Dates avec Tous les SÃ©parateurs â­â­â­â­

**Actuellement manquant :**
- `2018â€“2020` (tiret long)
- `Jan 2022 â†’ Mar 2023` (flÃ¨che)
- `2019 > PrÃ©sent` (chevron)

**Nouveaux patterns :**
```python
self.date_separators = [
    r'[-â€“â€”]',  # Tirets (court, moyen, long)
    r'[â†’>]',   # FlÃ¨ches
    r'(?:to|Ã |a)',  # Mots
]

self.date_pattern_with_range = (
    r'(' + '|'.join(self.date_patterns) + r')\s*'
    r'(' + '|'.join(self.date_separators) + r')\s*'
    r'(' + '|'.join(self.date_patterns) + r')'
)
```

---

### 2.2 Regroupement de Lignes Logiques â­â­â­â­

**ProblÃ¨me :**
```
Gestion de projets
Agile Scrum Jira
```
â†’ Doit Ãªtre reconnu comme une seule compÃ©tence

**Solution :**
```python
def _regroup_logical_lines(self, lines: List[str]) -> List[str]:
    """Regroupe les lignes qui appartiennent ensemble"""
    regrouped = []
    current_group = []
    
    for line in lines:
        line = line.strip()
        if not line:
            if current_group:
                regrouped.append(' '.join(current_group))
                current_group = []
            continue
        
        # Si la ligne est courte et la suivante aussi â†’ regrouper
        if len(line) < 50 and not line.endswith(('.', '!', '?')):
            current_group.append(line)
        else:
            if current_group:
                current_group.append(line)
                regrouped.append(' '.join(current_group))
                current_group = []
            else:
                regrouped.append(line)
    
    if current_group:
        regrouped.append(' '.join(current_group))
    
    return regrouped
```

---

### 2.3 Split CompÃ©tences par SÃ©parateurs â­â­â­â­

**Actuellement :** DÃ©tecte `"Python, React, SQL"` comme un seul mot

**Solution :**
```python
def _split_skills(self, text: str) -> List[str]:
    """Split les compÃ©tences selon les sÃ©parateurs"""
    separators = [',', ';', '/', 'â€¢', '-', '|', '\n']
    
    # Remplacer tous les sÃ©parateurs par virgule
    for sep in separators:
        text = text.replace(sep, ',')
    
    # Split et nettoyer
    skills = [s.strip() for s in text.split(',') if s.strip()]
    
    return skills
```

---

### 2.4 DÃ©tection du Nom Intelligente â­â­â­â­

**ProblÃ¨mes actuels :**
- Nom en banniÃ¨re
- Nom au milieu
- Nom dans une image
- Nom en majuscules
- Nom sur 2 lignes

**Solution :**
```python
def _extract_name_intelligent(self, lines: List[str]) -> str:
    """DÃ©tection intelligente du nom dans les 20 premiÃ¨res lignes"""
    candidates = []
    
    for i, line in enumerate(lines[:20]):
        line = line.strip()
        if not line or len(line) < 3:
            continue
        
        # Skip si email, tÃ©lÃ©phone, adresse
        if re.search(r'@|\.com|\d{5,}|http', line):
            continue
        
        # Score basÃ© sur critÃ¨res
        score = 0
        words = line.split()
        
        # CritÃ¨re 1 : Majuscules (nom souvent en caps)
        if line.isupper():
            score += 3
        elif line.istitle():
            score += 2
        
        # CritÃ¨re 2 : 2-4 mots (prÃ©nom + nom + Ã©ventuellement titre)
        if 2 <= len(words) <= 4:
            score += 2
        
        # CritÃ¨re 3 : Que des lettres (pas de chiffres)
        if all(re.match(r'^[A-ZÃ€-Ã¿a-z\'-]+$', word) for word in words):
            score += 2
        
        # CritÃ¨re 4 : Position (plus haut = plus probable)
        score += (20 - i) / 5
        
        # CritÃ¨re 5 : Taille police (si disponible via pdfplumber)
        # score += font_size_ratio
        
        candidates.append((line, score))
    
    # Retourner le candidat avec le meilleur score
    if candidates:
        candidates.sort(key=lambda x: x[1], reverse=True)
        return candidates[0][0]
    
    return ""
```

---

## ğŸ¯ Phase 3 : AmÃ©liorations AvancÃ©es (PrioritÃ© BASSE)

### 3.1 NLP avec spaCy â­â­â­

**Utilisation :**
- DÃ©tection automatique des entitÃ©s (noms, organisations, lieux)
- Extraction des mÃ©tiers
- ComprÃ©hension du contexte

```python
import spacy

class CVExtractorV3:
    def __init__(self):
        self.nlp_fr = spacy.load("fr_core_news_sm")
        self.nlp_en = spacy.load("en_core_web_sm")
    
    def _extract_entities_spacy(self, text: str, lang='fr') -> Dict:
        nlp = self.nlp_fr if lang == 'fr' else self.nlp_en
        doc = nlp(text)
        
        entities = {
            'persons': [],
            'organizations': [],
            'locations': [],
        }
        
        for ent in doc.ents:
            if ent.label_ == 'PER':
                entities['persons'].append(ent.text)
            elif ent.label_ == 'ORG':
                entities['organizations'].append(ent.text)
            elif ent.label_ in ['LOC', 'GPE']:
                entities['locations'].append(ent.text)
        
        return entities
```

---

### 3.2 DÃ©tection Multi-Langue â­â­

**Installation :**
```bash
pip install langdetect
```

**Code :**
```python
from langdetect import detect

def _detect_language(self, text: str) -> str:
    """DÃ©tecte la langue du CV"""
    try:
        return detect(text)  # 'fr', 'en', 'es', etc.
    except:
        return 'en'  # DÃ©faut
```

---

## ğŸ“¦ DÃ©pendances Additionnelles

```bash
# backend/requirements.txt

# DÃ©jÃ  installÃ©
pdfplumber==0.11.8
rapidfuzz==3.14.3
python-dateutil==2.9.0.post0

# Ã€ installer pour V3
spacy==3.7.2
langdetect==1.0.9
python-Levenshtein==0.25.0  # AccÃ©lÃ¨re rapidfuzz

# ModÃ¨les spaCy
# python -m spacy download fr_core_news_sm
# python -m spacy download en_core_web_sm
```

---

## ğŸ—“ï¸ Planning de DÃ©veloppement

### Sprint 1 (PrioritÃ© HAUTE) - 2-3 jours

- [x] IntÃ©gration ESCO (Ã©chantillon crÃ©Ã©) âœ…
- [ ] Tri spatial des blocs (x, y)
- [ ] Fuzzy matching sections
- [ ] Soft skills automatiques ESCO

### Sprint 2 (PrioritÃ© MOYENNE) - 2 jours

- [ ] Patterns dates Ã©tendus (â†’, â€“, >)
- [ ] Regroupement lignes logiques
- [ ] Split compÃ©tences
- [ ] DÃ©tection nom intelligente

### Sprint 3 (PrioritÃ© BASSE) - 1-2 jours

- [ ] NLP spaCy
- [ ] DÃ©tection multi-langue
- [ ] Extraction adresse complÃ¨te
- [ ] Langues + niveaux CEFR

---

## ğŸ’° Comparaison V2 vs V3

| CritÃ¨re | V2 (Actuel) | V3 (Futur) |
|---------|-------------|------------|
| **PrÃ©cision globale** | ~88% | ~93-95% |
| **CompÃ©tences (dataset)** | 96 skills | 13 000+ (ESCO) |
| **CV en colonnes** | âš ï¸ Moyen | âœ… Excellent |
| **Soft skills** | 43 manuels | Centaines (ESCO) |
| **Dates complexes** | âš ï¸ Partiel | âœ… Complet |
| **DÃ©tection sections** | âš ï¸ Stricte | âœ… Fuzzy |
| **Multi-langue** | FR/EN partiel | FR/EN/ES/DE/etc. |
| **NLP** | âŒ Non | âœ… spaCy |
| **CoÃ»t** | âœ… Gratuit | âœ… Gratuit |

---

## ğŸ¯ Recommandation

### Option 1 : Rester sur V2 âœ…
**Si :** PrÃ©cision de 88% est suffisante pour votre usage

### Option 2 : Sprint 1 uniquement (ESCO + Spatial) â­
**Si :** Vous voulez passer Ã  93% de prÃ©cision rapidement (2-3 jours)

### Option 3 : V3 complÃ¨te ğŸš€
**Si :** Vous visez l'excellence (95%+) et avez 5-7 jours de dÃ©veloppement

---

**Fichiers crÃ©Ã©s :**
- âœ… `backend/data/esco_skills_sample.json` (139 compÃ©tences)
- âœ… `backend/download_esco.py` (script d'installation ESCO)
- âœ… `CV_EXTRACTOR_V3_ROADMAP.md` (ce document)

**Prochaine Ã©tape :** ImplÃ©menter Sprint 1 (ESCO + Spatial) ?

